{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JJEEEFFFF/CE889-Labs/blob/main/lab_5/Assessment_and_forward_Propagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27063a6c",
      "metadata": {
        "id": "27063a6c",
        "outputId": "2ae385fa-20e2-4bae-c68b-165c5b18869f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final loss is  -0.5  at count  0\n",
            "[[0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5]] -0.5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def forwardPropagationSigmoid(xvalue):\n",
        "    sig = (1/(1+np.exp(-xvalue)))\n",
        "    return sig\n",
        "\n",
        "\n",
        "def assessment(y1,y2):\n",
        "    logYCalc = np.log(y2)\n",
        "    lossWB = -1*((y1*logYCalc + (1-y1)*(1-logYCalc)).sum())/8\n",
        "    return lossWB\n",
        "\n",
        "\n",
        "def gradientWeight(x,y1,y2):\n",
        "    gradientW = np.dot(x,(y2-y1).transpose())/12\n",
        "    return gradientW\n",
        "\n",
        "\n",
        "def gradientB(x,y1,y2):\n",
        "    gradient = ((y2-y1).sum()/8)\n",
        "    return gradient\n",
        "\n",
        "\n",
        "def updatingWeights(x,y1,y2):\n",
        "    learningRate = 0.01\n",
        "    \n",
        "    updatedW = w - learningRate*gradientWeight(x,y1,y2)\n",
        "    updatedB = b - learningRate*gradientB(x,y1,y2)\n",
        "    return updatedW, updatedB\n",
        "    \n",
        "\n",
        "xArray = [[1,6,8,0],[33,2,3,5],[1,6,6,7],[2,9,8,4],[5,6,9,6],[32,13,0,2]]\n",
        "x = np.array(xArray)\n",
        "w = np.full((6, 2), 0)\n",
        "\n",
        "b = np.full((2,4),0)\n",
        "\n",
        "\n",
        "testingData = [[0,12,0,3],[5,2,3,8],[11,5,4,7],[2,9,8,7],[5,10,9,9],[3,13,0,3]]\n",
        "x2 = np.array(testingData)\n",
        "\n",
        "#The Ground Truth is initialised with the given values\n",
        "y = np.array([[1,0,1,0],[0,1,0,1]])\n",
        "\n",
        "loss = None\n",
        "\n",
        "for i in range(3000):\n",
        "    calc = np.dot(w.transpose(),x) + b\n",
        "    yCalc = forwardPropagationSigmoid(calc)\n",
        "    loss = assessment(y,yCalc)\n",
        "    if loss<=0.0001:\n",
        "        print('Final loss is ',loss,' at count ', i)\n",
        "        \n",
        "        break\n",
        "    else:\n",
        "        wb =  updatingWeights(x2,y,yCalc)\n",
        "        w = wb[0]\n",
        "        b = wb[1]\n",
        "   \n",
        "calc2 = np.dot(w.transpose(),x2) +b\n",
        "y2Calc = forwardPropagationSigmoid(calc2)\n",
        "y2Loss = assessment(y,y2Calc)\n",
        "print(y2Calc , y2Loss)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "name": "Assessment and forward Propagation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}